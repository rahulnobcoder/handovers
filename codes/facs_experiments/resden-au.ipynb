{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8829695,"sourceType":"datasetVersion","datasetId":5312564},{"sourceId":8789836,"sourceType":"datasetVersion","datasetId":5284531}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport os\nimport cv2\nimport numpy as np \nfrom tqdm import tqdm\nimport pandas as pd\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T05:58:39.288537Z","iopub.execute_input":"2024-07-02T05:58:39.289199Z","iopub.status.idle":"2024-07-02T05:58:44.413239Z","shell.execute_reply.started":"2024-07-02T05:58:39.289163Z","shell.execute_reply":"2024-07-02T05:58:44.412251Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"folder_path = '/kaggle/input/faces-lm/frames'  # Replace with your folder path\nfolders=sorted(os.listdir(folder_path))","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:58:44.415004Z","iopub.execute_input":"2024-07-02T05:58:44.415852Z","iopub.status.idle":"2024-07-02T05:58:44.443485Z","shell.execute_reply.started":"2024-07-02T05:58:44.415815Z","shell.execute_reply":"2024-07-02T05:58:44.442789Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"paths=[]\nfor i in tqdm(range(len(folders))):\n    files=os.listdir(os.path.join(folder_path,folders[i]))\n    files.sort(key=lambda x: int(x.split('.')[0]))\n    files=[os.path.join(folder_path,folders[i],files[j]) for j in range(len(files))]\n    paths=paths+files","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:58:44.444484Z","iopub.execute_input":"2024-07-02T05:58:44.444755Z","iopub.status.idle":"2024-07-02T05:59:01.928109Z","shell.execute_reply.started":"2024-07-02T05:58:44.444732Z","shell.execute_reply":"2024-07-02T05:59:01.927206Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"100%|██████████| 27/27 [00:17<00:00,  1.55it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_csv_id(file_path):\n\n    # Extract the filename without extension\n    filename = os.path.basename(file_path)  # RightVideoSN001.csv\n\n    # Extract the identifier ('1' or '11')\n    if filename.startswith('RightVideoSN'):\n        identifier = filename[len('RightVideoSN'):]  # Get '001' or '011'\n        identifier = identifier.lstrip('0').split('.')[0]  # Remove leading zeros\n\n    return int(identifier)\ndef get_id(path):\n\n    # Split the path by '/'\n    parts = path.split('/')\n\n    # Get the directory name that contains the image\n    dirname = parts[-2]  # RightVideoSN011\n\n    # Extract the relevant parts from the directory name\n    if dirname.startswith('RightVideoSN'):\n        identifier = dirname[len('RightVideoSN'):]  # Get SN011 -> 011\n        identifier = identifier.lstrip('0')  # Remove leading zeros\n\n    # Get the image number from the filename\n    filename = parts[-1]  # 240.jpg\n    image_number = os.path.splitext(filename)[0]  # 240\n\n    return int(identifier),int(image_number)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:59:07.906811Z","iopub.execute_input":"2024-07-02T05:59:07.907169Z","iopub.status.idle":"2024-07-02T05:59:07.914574Z","shell.execute_reply.started":"2024-07-02T05:59:07.907140Z","shell.execute_reply":"2024-07-02T05:59:07.913651Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"folder_path = '/kaggle/input/labels-csv/labels_csv'\ncsv_path=[]\nfor root, dirs, files in os.walk(folder_path):\n    for file_name in files:\n        file_path = os.path.join(root, file_name)\n        csv_path.append(file_path)\ncsv_path=sorted(csv_path)\ncsv={}\nfor file in csv_path:\n    df=pd.read_csv(file)\n    ide=get_csv_id(file)\n    csv[ide]=df","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:59:08.247275Z","iopub.execute_input":"2024-07-02T05:59:08.247859Z","iopub.status.idle":"2024-07-02T05:59:08.586015Z","shell.execute_reply.started":"2024-07-02T05:59:08.247829Z","shell.execute_reply":"2024-07-02T05:59:08.585025Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"labels=[]\nfor file in tqdm(paths):\n    ide,image=get_id(file)\n    try:\n        label=np.array(csv[ide].iloc[image])\n        label[label > 0]=1\n        labels.append(label)\n    except IndexError as e:\n        print(f\"IndexError occurred: {ide}\")\n        print(f\"Check ide={ide} and image={image} against csv indices.\")\nlabels=np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:20:19.311432Z","iopub.execute_input":"2024-07-02T06:20:19.311798Z","iopub.status.idle":"2024-07-02T06:20:21.764195Z","shell.execute_reply.started":"2024-07-02T06:20:19.311762Z","shell.execute_reply":"2024-07-02T06:20:21.763300Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 32723/32723 [00:02<00:00, 13539.07it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Get indices where all elements in rows are zero\nzero_indices = np.where(~labels.any(axis=1))[0]\n\nprint(\"Indices where all elements in rows are zero:\")","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:24:01.021469Z","iopub.execute_input":"2024-07-02T06:24:01.022306Z","iopub.status.idle":"2024-07-02T06:24:01.028742Z","shell.execute_reply.started":"2024-07-02T06:24:01.022274Z","shell.execute_reply":"2024-07-02T06:24:01.027837Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Indices where all elements in rows are zero:\n12154\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(labels,columns=csv[1].columns).to_csv('labels.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:21:26.462399Z","iopub.execute_input":"2024-07-02T06:21:26.463241Z","iopub.status.idle":"2024-07-02T06:21:26.605505Z","shell.execute_reply.started":"2024-07-02T06:21:26.463204Z","shell.execute_reply":"2024-07-02T06:21:26.604567Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"frames=[]\ntarget_size=(224, 224)\nfor i in tqdm(range(len(paths))):\n    img=cv2.imread(paths[i],0)\n    resized_img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n    rgb_image = cv2.cvtColor(resized_img, cv2.COLOR_GRAY2RGB)\n    frames.append(rgb_image)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:59:10.960783Z","iopub.execute_input":"2024-07-02T05:59:10.961068Z","iopub.status.idle":"2024-07-02T06:03:32.688267Z","shell.execute_reply.started":"2024-07-02T05:59:10.961043Z","shell.execute_reply":"2024-07-02T06:03:32.687302Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 32723/32723 [04:21<00:00, 125.03it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader,WeightedRandomSampler\nimport numpy as np\nfrom torchvision import transforms\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:03:32.689605Z","iopub.execute_input":"2024-07-02T06:03:32.689901Z","iopub.status.idle":"2024-07-02T06:03:32.695051Z","shell.execute_reply.started":"2024-07-02T06:03:32.689874Z","shell.execute_reply":"2024-07-02T06:03:32.694114Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image,torch.tensor(label, dtype=torch.float32)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:03:32.697762Z","iopub.execute_input":"2024-07-02T06:03:32.698214Z","iopub.status.idle":"2024-07-02T06:03:32.705785Z","shell.execute_reply.started":"2024-07-02T06:03:32.698182Z","shell.execute_reply":"2024-07-02T06:03:32.704866Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.Resize((224, 224)),  # Resize to 224x224 if needed (based on model input requirements)\n    transforms.ToTensor(),  # Convert PIL Image to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize (ImageNet stats)\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:03:32.706800Z","iopub.execute_input":"2024-07-02T06:03:32.707424Z","iopub.status.idle":"2024-07-02T06:03:32.715986Z","shell.execute_reply.started":"2024-07-02T06:03:32.707393Z","shell.execute_reply":"2024-07-02T06:03:32.715154Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset = ImageDataset(frames, labels, transform=transform)\n\n# Split the dataset into training and validation sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:04:47.901204Z","iopub.execute_input":"2024-07-02T06:04:47.901616Z","iopub.status.idle":"2024-07-02T06:04:47.910845Z","shell.execute_reply.started":"2024-07-02T06:04:47.901585Z","shell.execute_reply":"2024-07-02T06:04:47.910062Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class DenseBlock(nn.Module):\n    def __init__(self, in_channels, growth_rate, num_layers):\n        super(DenseBlock, self).__init__()\n        self.layers = nn.ModuleList()\n        for i in range(num_layers):\n            self.layers.append(self._make_layer(in_channels + i * growth_rate, growth_rate))\n\n    def _make_layer(self, in_channels, growth_rate):\n        layer = nn.Sequential(\n            nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1),\n            nn.BatchNorm2d(growth_rate),\n            nn.ReLU(inplace=True)\n        )\n        return layer\n\n    def forward(self, x):\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(torch.cat(features, 1))\n            features.append(new_feature)\n        return torch.cat(features, 1)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:03:32.780845Z","iopub.execute_input":"2024-07-02T06:03:32.781367Z","iopub.status.idle":"2024-07-02T06:03:32.793472Z","shell.execute_reply.started":"2024-07-02T06:03:32.781318Z","shell.execute_reply":"2024-07-02T06:03:32.792039Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip_connection = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip_connection = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        identity = self.skip_connection(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:03:32.795529Z","iopub.execute_input":"2024-07-02T06:03:32.796901Z","iopub.status.idle":"2024-07-02T06:03:32.825930Z","shell.execute_reply.started":"2024-07-02T06:03:32.796869Z","shell.execute_reply":"2024-07-02T06:03:32.824530Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class ResiDenNet(nn.Module):\n    def __init__(self, growth_rate=32, num_layers=4, num_classes=12):\n        super(ResiDenNet, self).__init__()\n        self.initial_conv = nn.Conv2d(3, growth_rate * 2, kernel_size=7, stride=2, padding=3)\n        self.initial_bn = nn.BatchNorm2d(growth_rate * 2)\n        self.initial_relu = nn.ReLU(inplace=True)\n        self.initial_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        \n        self.dense_block1 = DenseBlock(growth_rate * 2, growth_rate, num_layers)\n        self.trans1 = self._transition_layer(growth_rate * (2 + num_layers), growth_rate * 2)\n\n        self.res_block = ResidualBlock(growth_rate * 2, growth_rate * 2)\n        \n        self.dense_block2 = DenseBlock(growth_rate * 2, growth_rate, num_layers)\n        self.trans2 = self._transition_layer(growth_rate * (2 + num_layers), growth_rate * 2)\n\n        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(growth_rate * 2, num_classes)\n        self.sigmoid = nn.Sigmoid()\n\n    def _transition_layer(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        x = self.initial_conv(x)\n        x = self.initial_bn(x)\n        x = self.initial_relu(x)\n        x = self.initial_pool(x)\n\n        x = self.dense_block1(x)\n        x = self.trans1(x)\n        \n        x = self.res_block(x)\n        \n        x = self.dense_block2(x)\n        x = self.trans2(x)\n\n        x = self.global_pool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        x = self.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:03:32.828086Z","iopub.execute_input":"2024-07-02T06:03:32.829248Z","iopub.status.idle":"2024-07-02T06:03:32.868235Z","shell.execute_reply.started":"2024-07-02T06:03:32.829216Z","shell.execute_reply":"2024-07-02T06:03:32.867243Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ResiDenNet().to(device)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:03:32.871186Z","iopub.execute_input":"2024-07-02T06:03:32.871530Z","iopub.status.idle":"2024-07-02T06:03:33.082680Z","shell.execute_reply.started":"2024-07-02T06:03:32.871493Z","shell.execute_reply":"2024-07-02T06:03:33.081673Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"num_epochs = 20\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n    \n    print(f\"Validation Loss: {val_loss/len(val_loader)}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:04:51.824654Z","iopub.execute_input":"2024-07-02T06:04:51.825011Z","iopub.status.idle":"2024-07-02T06:20:19.308980Z","shell.execute_reply.started":"2024-07-02T06:04:51.824982Z","shell.execute_reply":"2024-07-02T06:20:19.307728Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.7856090814057142\nValidation Loss: 0.7214972373915882\nEpoch 2, Loss: 0.7083842315516629\nValidation Loss: 0.7016124766047408\nEpoch 3, Loss: 0.697740518784785\nValidation Loss: 0.6966684614739767\nEpoch 4, Loss: 0.695117383722275\nValidation Loss: 0.6944540384339123\nEpoch 5, Loss: 0.694134972325466\nValidation Loss: 0.6938022427442597\nEpoch 6, Loss: 0.6935142323793217\nValidation Loss: 0.692061056741854\nEpoch 7, Loss: 0.6881064255886753\nValidation Loss: 0.6854361917914413\nEpoch 8, Loss: 0.6850937698786949\nValidation Loss: 0.6854333807782429\nEpoch 9, Loss: 0.6844148592197852\nValidation Loss: 0.6839474032564861\nEpoch 10, Loss: 0.6842028278134245\nValidation Loss: 0.6837929463968044\nEpoch 11, Loss: 0.6839261607372717\nValidation Loss: 0.683530414395216\nEpoch 12, Loss: 0.6836947245621128\nValidation Loss: 0.6842107525685939\nEpoch 13, Loss: 0.683571392290467\nValidation Loss: 0.6834773534681738\nEpoch 14, Loss: 0.6830260255106785\nValidation Loss: 0.6818618274316555\nEpoch 15, Loss: 0.6809931850840902\nValidation Loss: 0.6805859652961173\nEpoch 16, Loss: 0.6802252447357691\nValidation Loss: 0.6800843564475455\nEpoch 17, Loss: 0.6800127264489767\nValidation Loss: 0.67978505099692\nEpoch 18, Loss: 0.6797948163070958\nValidation Loss: 0.6796264633899782\nEpoch 19, Loss: 0.6796417985934768\nValidation Loss: 0.6794813057271446\nEpoch 20, Loss: 0.6794905690192011\nValidation Loss: 0.6795882390766609\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nmodel.eval()  # Set model to evaluation mode\npredictions = []\ntrue_labels = []\n\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        \n        # Apply sigmoid activation to outputs to get probabilities\n        probabilities = torch.sigmoid(outputs)\n        \n        # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n        threshold = 0.5\n        predicted_labels = (probabilities > threshold).int()\n        \n        predictions.extend(predicted_labels.cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())  # Optional: Collect true labels for evaluation\n\n# Now predictions contains the predicted labels (binary) for your test dataset\npredictions = np.array(predictions)\nprint(predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:52:28.309212Z","iopub.execute_input":"2024-07-02T05:52:28.309684Z","iopub.status.idle":"2024-07-02T05:52:37.305057Z","shell.execute_reply.started":"2024-07-02T05:52:28.309656Z","shell.execute_reply":"2024-07-02T05:52:37.304082Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, concatenate\nfrom tensorflow.keras.models import Model\n\n# Define the ResiDen model\ndef ResiDen(input_shape):\n    inputs = Input(shape=input_shape)\n\n    # Residual Dense Network Layers\n    x = Conv2D(48, (3, 3), activation='relu', padding='same')(inputs)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Flatten()(x)\n    residen_features = Dense(4096, activation='relu')(x)\n    \n    model = Model(inputs, residen_features)\n    return model\n\n# Define the basic CNN model\ndef BasicCNN(input_shape):\n    inputs = Input(shape=input_shape)\n\n    x = Conv2D(48, (3, 3), activation='relu', padding='same')(inputs)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Flatten()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.4)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    cnn_features = Dense(2048, activation='relu')(x)\n    \n    model = Model(inputs, cnn_features)\n    return model\n\n# Define the combined model\ndef CombinedModel(input_shape):\n    # ResiDen model\n    residen_model = ResiDen(input_shape)\n    residen_input = residen_model.input\n    residen_output = residen_model.output\n\n    # Basic CNN model\n    cnn_model = BasicCNN(input_shape)\n    cnn_input = cnn_model.input\n    cnn_output = cnn_model.output\n\n    # Concatenate features from both models\n    combined_features = concatenate([residen_output, cnn_output])\n\n    # Final fully connected layers\n    x = Dense(512, activation='relu')(combined_features)\n    x = Dense(2048, activation='relu')(x)\n    x = Dense(2048, activation='relu')(x)\n    outputs = Dense(num_classes, activation='softmax')(x)  # Assuming a classification task\n\n    model = Model(inputs=[residen_input, cnn_input], outputs=outputs)\n    return model\n\n# Define input shape and number of classes\ninput_shape = (64, 64, 3)  # Example input shape, adjust as needed\nnum_classes = 7  # Example number of classes, adjust as needed\n\n# Create the combined model\nmodel = CombinedModel(input_shape)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print the model summary\nmodel.summary()\n","metadata":{},"execution_count":null,"outputs":[]}]}